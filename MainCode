# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

"""
The task involves building a model to classify whether a given tweet is about a real disaster or not. 
The dataset includes tweets with corresponding keywords and locations, though these may be missing for some entries. 
The training data is labeled, whereas the test data is not. The goal is to predict the 'target' label for the test set tweets.
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import re
import os
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
import seaborn as sns
from sklearn.metrics import classification_report

# Load data
train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')
test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')

# Preserve the 'id' column in the test DataFrame for submission
test_ids = test['id']

# Drop unnecessary columns from train data
columns_to_drop = ['keyword', 'location']
train = train.drop(columns=[col for col in columns_to_drop if col in train.columns])
test = test.drop(columns=[col for col in columns_to_drop if col in test.columns])

# Define text cleaning function
stop_words = set(stopwords.words('english'))
def clean_text(text):
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)
    text = re.sub(r'[^a-z\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Apply text cleaning
train['text'] = train['text'].apply(clean_text)
test['text'] = test['text'].apply(clean_text)

# Prepare data for training
X = train['text'].values
y = train['target'].values

vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
X_tfidf = vectorizer.fit_transform(X).toarray()

# Split the data
X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Reshape for CNN model input
X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_val_cnn = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))

# Define the CNN model
input_shape = (X_train.shape[1], 1)
model = Sequential([
    Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.summary()

# Compile the model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
num_epochs = 10
batch_size = 64
history = model.fit(X_train_cnn, y_train, epochs=num_epochs, validation_data=(X_val_cnn, y_val), batch_size=batch_size, verbose=2)

# Plot training & validation accuracy values
plt.figure(figsize=(10, 6))
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='b', linestyle='--')
plt.plot(history.history['accuracy'], label='Training Accuracy', color='g')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Evaluate the model
loss, accuracy = model.evaluate(X_val_cnn, y_val, verbose=0)
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy:.4f}')

# Preprocess test data
xt = test['text'].values
xt_tfidf = vectorizer.transform(xt).toarray()
xt_cnn = xt_tfidf.reshape((xt_tfidf.shape[0], xt_tfidf.shape[1], 1))

# Make predictions on the test data
pred = model.predict(xt_cnn)

# Convert predictions to class labels
pred_classes = (pred > 0.5).astype(int).reshape(-1)

# Add predictions to the test DataFrame
test['target'] = pred_classes

# Save the test DataFrame with predictions to a CSV file
submission = pd.DataFrame({'id': test_ids, 'target': pred_classes})
submission.to_csv("/kaggle/working/submission.csv", index=False)

# Verify the file exists
print(os.listdir('/kaggle/working/'))


"""
The CNN model performs reasonably well in classifying tweets related to real disasters. 
The text preprocessing steps, including cleaning and TF-IDF vectorization, were crucial in preparing the data for the model. 
While the model shows good accuracy, further improvements can be made by exploring different model architectures, hyperparameter tuning, and incorporating additional features such as keyword and location information.
Future work could involve using more advanced NLP models like BERT for potentially better performance.
"""
